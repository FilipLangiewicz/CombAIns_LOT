{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80c20d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "train = pd.read_csv(\"hackaton_students_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6c556ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:05<00:00,  9.44it/s]5<00:00, 10.75it/s, Describe variable: top_3_section]                  \n",
      "Summarize dataset: 100%|██████████| 505/505 [00:58<00:00,  8.64it/s, Completed]                                                             \n",
      "Generate report structure: 100%|██████████| 1/1 [00:13<00:00, 13.15s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:10<00:00, 10.90s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s]\n"
     ]
    }
   ],
   "source": [
    "profile = ProfileReport(train, title=\"Raport danych: Hackaton Students\", explorative=True)\n",
    "profile.to_file(\"profiling_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "713378e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - pytorch\n",
      " - conda-forge\n",
      " - bioconda\n",
      " - defaults\n",
      " - anaconda\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: c:\\Users\\Mikolaj\\anaconda3\\envs\\djangovenv\n",
      "\n",
      "  added / updated specs:\n",
      "    - cpuonly\n",
      "    - pytorch\n",
      "    - torchaudio\n",
      "    - torchvision\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    brotli-python-1.0.9        |  py312h5da7b33_9         347 KB\n",
      "    cffi-1.17.1                |  py312h827c3e9_1         311 KB\n",
      "    charset-normalizer-3.4.1   |     pyhd8ed1ab_0          46 KB  conda-forge\n",
      "    cpuonly-2.0                |                0           2 KB  pytorch\n",
      "    filelock-3.18.0            |     pyhd8ed1ab_0          17 KB  conda-forge\n",
      "    freetype-2.10.4            |       h546665d_1         489 KB  conda-forge\n",
      "    h2-4.2.0                   |     pyhd8ed1ab_0          53 KB  conda-forge\n",
      "    hpack-4.1.0                |     pyhd8ed1ab_0          30 KB  conda-forge\n",
      "    hyperframe-6.1.0           |     pyhd8ed1ab_0          17 KB  conda-forge\n",
      "    idna-3.10                  |     pyhd8ed1ab_1          49 KB  conda-forge\n",
      "    intel-openmp-2025.0.4      |    h57928b3_1528         1.8 MB  conda-forge\n",
      "    jinja2-3.1.6               |     pyhd8ed1ab_0         110 KB  conda-forge\n",
      "    jpeg-9e                    |       h8ffe710_2         366 KB  conda-forge\n",
      "    lcms2-2.16                 |       hb4a4139_0         566 KB\n",
      "    libdeflate-1.22            |       h2466b09_0         152 KB  conda-forge\n",
      "    libjpeg-turbo-2.1.4        |       hcfcfb64_0         1.3 MB  conda-forge\n",
      "    libpng-1.6.39              |       h8cc25b3_0         369 KB\n",
      "    libtiff-4.5.1              |       h44ae7cf_1         1.0 MB\n",
      "    libuv-1.50.0               |       h2466b09_0         285 KB  conda-forge\n",
      "    libwebp-1.5.0              |       h3b0e114_0          70 KB  conda-forge\n",
      "    libxml2-2.13.7             |       h866ff63_0         2.9 MB\n",
      "    markupsafe-3.0.2           |     pyhe1237c8_1          14 KB  conda-forge\n",
      "    mkl-service-2.4.0          |  py312h827c3e9_2          64 KB\n",
      "    mkl_fft-1.3.11             |  py312h827c3e9_0         169 KB\n",
      "    mkl_random-1.2.8           |  py312h0158946_0         252 KB\n",
      "    mpmath-1.3.0               |     pyhd8ed1ab_1         429 KB  conda-forge\n",
      "    numpy-2.0.1                |  py312hfd52020_1          11 KB\n",
      "    numpy-base-2.0.1           |  py312h4dde369_1         7.1 MB\n",
      "    openjpeg-2.5.2             |       hae555c5_0         268 KB\n",
      "    pillow-11.1.0              |  py312h096bfcc_0         902 KB\n",
      "    pycparser-2.22             |     pyh29332c3_1         108 KB  conda-forge\n",
      "    pysocks-1.7.1              |     pyh09c184e_7          21 KB  conda-forge\n",
      "    pytorch-2.5.1              |     py3.12_cpu_0       150.6 MB  pytorch\n",
      "    pytorch-mutex-1.0          |              cpu           3 KB  pytorch\n",
      "    pyyaml-6.0.2               |     pyhe1237c8_2          44 KB  conda-forge\n",
      "    requests-2.32.3            |     pyhd8ed1ab_1          57 KB  conda-forge\n",
      "    sympy-1.13.3               |     pyh04b8f61_5         4.3 MB  conda-forge\n",
      "    torchaudio-2.5.1           |        py312_cpu         5.9 MB  pytorch\n",
      "    torchvision-0.20.1         |        py312_cpu         6.7 MB  pytorch\n",
      "    urllib3-2.4.0              |     pyhd8ed1ab_0          98 KB  conda-forge\n",
      "    win_inet_pton-1.1.0        |     pyh7428d3b_8           9 KB  conda-forge\n",
      "    zstandard-0.23.0           |  py312h4fc1ca9_1         351 KB\n",
      "    zstd-1.5.6                 |       h8880b57_0         708 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       188.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  blas               conda-forge/win-64::blas-1.0-mkl \n",
      "  brotli-python      pkgs/main/win-64::brotli-python-1.0.9-py312h5da7b33_9 \n",
      "  certifi            conda-forge/noarch::certifi-2025.1.31-pyhd8ed1ab_0 \n",
      "  cffi               pkgs/main/win-64::cffi-1.17.1-py312h827c3e9_1 \n",
      "  charset-normalizer conda-forge/noarch::charset-normalizer-3.4.1-pyhd8ed1ab_0 \n",
      "  cpuonly            pytorch/noarch::cpuonly-2.0-0 \n",
      "  filelock           conda-forge/noarch::filelock-3.18.0-pyhd8ed1ab_0 \n",
      "  freetype           conda-forge/win-64::freetype-2.10.4-h546665d_1 \n",
      "  h2                 conda-forge/noarch::h2-4.2.0-pyhd8ed1ab_0 \n",
      "  hpack              conda-forge/noarch::hpack-4.1.0-pyhd8ed1ab_0 \n",
      "  hyperframe         conda-forge/noarch::hyperframe-6.1.0-pyhd8ed1ab_0 \n",
      "  idna               conda-forge/noarch::idna-3.10-pyhd8ed1ab_1 \n",
      "  intel-openmp       conda-forge/win-64::intel-openmp-2025.0.4-h57928b3_1528 \n",
      "  jinja2             conda-forge/noarch::jinja2-3.1.6-pyhd8ed1ab_0 \n",
      "  jpeg               conda-forge/win-64::jpeg-9e-h8ffe710_2 \n",
      "  lcms2              pkgs/main/win-64::lcms2-2.16-hb4a4139_0 \n",
      "  lerc               conda-forge/win-64::lerc-4.0.0-h63175ca_0 \n",
      "  libdeflate         conda-forge/win-64::libdeflate-1.22-h2466b09_0 \n",
      "  libhwloc           conda-forge/win-64::libhwloc-2.11.2-default_ha69328c_1001 \n",
      "  libiconv           conda-forge/win-64::libiconv-1.18-h135ad9c_1 \n",
      "  libjpeg-turbo      conda-forge/win-64::libjpeg-turbo-2.1.4-hcfcfb64_0 \n",
      "  libpng             pkgs/main/win-64::libpng-1.6.39-h8cc25b3_0 \n",
      "  libtiff            pkgs/main/win-64::libtiff-4.5.1-h44ae7cf_1 \n",
      "  libuv              conda-forge/win-64::libuv-1.50.0-h2466b09_0 \n",
      "  libwebp            conda-forge/win-64::libwebp-1.5.0-h3b0e114_0 \n",
      "  libwebp-base       conda-forge/win-64::libwebp-base-1.5.0-h3b0e114_0 \n",
      "  libwinpthread      conda-forge/win-64::libwinpthread-12.0.0.r4.gg4f2fc60ca-h57928b3_9 \n",
      "  libxml2            pkgs/main/win-64::libxml2-2.13.7-h866ff63_0 \n",
      "  lz4-c              conda-forge/win-64::lz4-c-1.9.4-hcfcfb64_0 \n",
      "  markupsafe         conda-forge/noarch::markupsafe-3.0.2-pyhe1237c8_1 \n",
      "  mkl                conda-forge/win-64::mkl-2023.1.0-h6a75c08_48682 \n",
      "  mkl-service        pkgs/main/win-64::mkl-service-2.4.0-py312h827c3e9_2 \n",
      "  mkl_fft            pkgs/main/win-64::mkl_fft-1.3.11-py312h827c3e9_0 \n",
      "  mkl_random         pkgs/main/win-64::mkl_random-1.2.8-py312h0158946_0 \n",
      "  mpmath             conda-forge/noarch::mpmath-1.3.0-pyhd8ed1ab_1 \n",
      "  networkx           conda-forge/noarch::networkx-3.4.2-pyh267e887_2 \n",
      "  numpy              pkgs/main/win-64::numpy-2.0.1-py312hfd52020_1 \n",
      "  numpy-base         pkgs/main/win-64::numpy-base-2.0.1-py312h4dde369_1 \n",
      "  openjpeg           pkgs/main/win-64::openjpeg-2.5.2-hae555c5_0 \n",
      "  pillow             pkgs/main/win-64::pillow-11.1.0-py312h096bfcc_0 \n",
      "  pycparser          conda-forge/noarch::pycparser-2.22-pyh29332c3_1 \n",
      "  pysocks            conda-forge/noarch::pysocks-1.7.1-pyh09c184e_7 \n",
      "  pytorch            pytorch/win-64::pytorch-2.5.1-py3.12_cpu_0 \n",
      "  pytorch-mutex      pytorch/noarch::pytorch-mutex-1.0-cpu \n",
      "  pyyaml             conda-forge/noarch::pyyaml-6.0.2-pyhe1237c8_2 \n",
      "  requests           conda-forge/noarch::requests-2.32.3-pyhd8ed1ab_1 \n",
      "  sympy              conda-forge/noarch::sympy-1.13.3-pyh04b8f61_5 \n",
      "  tbb                conda-forge/win-64::tbb-2021.13.0-h62715c5_1 \n",
      "  torchaudio         pytorch/win-64::torchaudio-2.5.1-py312_cpu \n",
      "  torchvision        pytorch/win-64::torchvision-0.20.1-py312_cpu \n",
      "  urllib3            conda-forge/noarch::urllib3-2.4.0-pyhd8ed1ab_0 \n",
      "  win_inet_pton      conda-forge/noarch::win_inet_pton-1.1.0-pyh7428d3b_8 \n",
      "  yaml               conda-forge/win-64::yaml-0.2.5-h8ffe710_2 \n",
      "  zstandard          pkgs/main/win-64::zstandard-0.23.0-py312h4fc1ca9_1 \n",
      "  zstd               pkgs/main/win-64::zstd-1.5.6-h8880b57_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages: ...working...\n",
      "pytorch-2.5.1        | 150.6 MB  |            |   0% \n",
      "\n",
      "numpy-base-2.0.1     | 7.1 MB    |            |   0% \u001b[A\n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    |            |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "torchaudio-2.5.1     | 5.9 MB    |            |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sympy-1.13.3         | 4.3 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libxml2-2.13.7       | 2.9 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "intel-openmp-2025.0. | 1.8 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libjpeg-turbo-2.1.4  | 1.3 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libtiff-4.5.1        | 1.0 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pillow-11.1.0        | 902 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "zstd-1.5.6           | 708 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lcms2-2.16           | 566 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "freetype-2.10.4      | 489 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mpmath-1.3.0         | 429 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libpng-1.6.39        | 369 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "jpeg-9e              | 366 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "zstandard-0.23.0     | 351 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "brotli-python-1.0.9  | 347 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cffi-1.17.1          | 311 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    |            |   0% \u001b[A\u001b[A\n",
      "\n",
      "numpy-base-2.0.1     | 7.1 MB    |            |   0% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sympy-1.13.3         | 4.3 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "torchaudio-2.5.1     | 5.9 MB    |            |   0% \u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  |            |   0% \n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | 2          |   3% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sympy-1.13.3         | 4.3 MB    | 2          |   3% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  |            |   0% \n",
      "\n",
      "\n",
      "\n",
      "torchaudio-2.5.1     | 5.9 MB    | 2          |   3% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "numpy-base-2.0.1     | 7.1 MB    | 5          |   6% \u001b[A\n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | 6          |   6% \u001b[A\u001b[A\n",
      "\n",
      "numpy-base-2.0.1     | 7.1 MB    | #5         |  16% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "torchaudio-2.5.1     | 5.9 MB    | #          |  10% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sympy-1.13.3         | 4.3 MB    | 5          |   5% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  |            |   0% \n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | #          |  10% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | #2         |  13% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sympy-1.13.3         | 4.3 MB    | 7          |   7% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | #5         |  15% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sympy-1.13.3         | 4.3 MB    | #9         |  20% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  |            |   0% \n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | #9         |  20% \u001b[A\u001b[A\n",
      "\n",
      "numpy-base-2.0.1     | 7.1 MB    | ##1        |  21% \u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  |            |   1% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sympy-1.13.3         | 4.3 MB    | ##6        |  27% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "torchaudio-2.5.1     | 5.9 MB    | #3         |  14% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | ##3        |  23% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "torchaudio-2.5.1     | 5.9 MB    | #6         |  17% \u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  |            |   1% \n",
      "\n",
      "\n",
      "\n",
      "torchaudio-2.5.1     | 5.9 MB    | ##3        |  23% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "numpy-base-2.0.1     | 7.1 MB    | ##9        |  29% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "torchaudio-2.5.1     | 5.9 MB    | ###1       |  32% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sympy-1.13.3         | 4.3 MB    | ###1       |  32% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  |            |   1% \n",
      "\n",
      "numpy-base-2.0.1     | 7.1 MB    | ###8       |  39% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "torchaudio-2.5.1     | 5.9 MB    | ####1      |  41% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sympy-1.13.3         | 4.3 MB    | ###7       |  38% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sympy-1.13.3         | 4.3 MB    | ####6      |  47% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "numpy-base-2.0.1     | 7.1 MB    | ####3      |  44% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sympy-1.13.3         | 4.3 MB    | #####4     |  55% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "torchaudio-2.5.1     | 5.9 MB    | ####7      |  48% \u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  |            |   1% \n",
      "\n",
      "numpy-base-2.0.1     | 7.1 MB    | #####3     |  54% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sympy-1.13.3         | 4.3 MB    | ######1    |  61% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "torchaudio-2.5.1     | 5.9 MB    | ######     |  60% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "numpy-base-2.0.1     | 7.1 MB    | ######1    |  61% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "torchaudio-2.5.1     | 5.9 MB    | ######7    |  67% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "numpy-base-2.0.1     | 7.1 MB    | #######3   |  74% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "torchaudio-2.5.1     | 5.9 MB    | #######8   |  78% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sympy-1.13.3         | 4.3 MB    | ######7    |  67% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "numpy-base-2.0.1     | 7.1 MB    | ########5  |  85% \u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  |            |   1% \n",
      "\n",
      "\n",
      "\n",
      "torchaudio-2.5.1     | 5.9 MB    | ########6  |  86% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sympy-1.13.3         | 4.3 MB    | #######3   |  73% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 1          |   1% \n",
      "\n",
      "numpy-base-2.0.1     | 7.1 MB    | #########3 |  93% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "torchaudio-2.5.1     | 5.9 MB    | #########5 |  96% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sympy-1.13.3         | 4.3 MB    | #######9   |  80% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 1          |   1% \n",
      "\n",
      "\n",
      "\n",
      "torchaudio-2.5.1     | 5.9 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "numpy-base-2.0.1     | 7.1 MB    | ########## | 100% \u001b[A\n",
      "\n",
      "numpy-base-2.0.1     | 7.1 MB    | ########## | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sympy-1.13.3         | 4.3 MB    | #########  |  91% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 1          |   1% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "intel-openmp-2025.0. | 1.8 MB    |            |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libxml2-2.13.7       | 2.9 MB    |            |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "intel-openmp-2025.0. | 1.8 MB    | ###1       |  32% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libxml2-2.13.7       | 2.9 MB    | 1          |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 1          |   2% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sympy-1.13.3         | 4.3 MB    | #########7 |  97% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | ##6        |  26% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "intel-openmp-2025.0. | 1.8 MB    | #######8   |  78% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libxml2-2.13.7       | 2.9 MB    | 9          |   9% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 1          |   2% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sympy-1.13.3         | 4.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libxml2-2.13.7       | 2.9 MB    | ###1       |  31% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "intel-openmp-2025.0. | 1.8 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libxml2-2.13.7       | 2.9 MB    | #####      |  50% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 1          |   2% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libtiff-4.5.1        | 1.0 MB    | 1          |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libjpeg-turbo-2.1.4  | 1.3 MB    | 1          |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libxml2-2.13.7       | 2.9 MB    | ########6  |  87% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 1          |   2% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libtiff-4.5.1        | 1.0 MB    | #####6     |  56% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libtiff-4.5.1        | 1.0 MB    | #########2 |  93% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 2          |   2% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libxml2-2.13.7       | 2.9 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libtiff-4.5.1        | 1.0 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "zstd-1.5.6           | 708 KB    | 2          |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pillow-11.1.0        | 902 KB    | 1          |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 2          |   2% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libjpeg-turbo-2.1.4  | 1.3 MB    | 5          |   6% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pillow-11.1.0        | 902 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "zstd-1.5.6           | 708 KB    | ########3  |  84% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "zstd-1.5.6           | 708 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lcms2-2.16           | 566 KB    | 2          |   3% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 2          |   2% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libjpeg-turbo-2.1.4  | 1.3 MB    | #5         |  15% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lcms2-2.16           | 566 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "freetype-2.10.4      | 489 KB    | 3          |   3% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mpmath-1.3.0         | 429 KB    | 3          |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 2          |   3% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mpmath-1.3.0         | 429 KB    | ####       |  41% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mpmath-1.3.0         | 429 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libjpeg-turbo-2.1.4  | 1.3 MB    | ##         |  20% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 2          |   3% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libpng-1.6.39        | 369 KB    | 4          |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "freetype-2.10.4      | 489 KB    | ####2      |  43% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libpng-1.6.39        | 369 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "freetype-2.10.4      | 489 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libjpeg-turbo-2.1.4  | 1.3 MB    | ##9        |  30% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 3          |   3% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "jpeg-9e              | 366 KB    | 4          |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "zstandard-0.23.0     | 351 KB    | 4          |   5% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "jpeg-9e              | 366 KB    | #####2     |  52% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libjpeg-turbo-2.1.4  | 1.3 MB    | ###6       |  37% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 3          |   3% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "zstandard-0.23.0     | 351 KB    | ######3    |  64% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "zstandard-0.23.0     | 351 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "jpeg-9e              | 366 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libjpeg-turbo-2.1.4  | 1.3 MB    | ####5      |  45% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "brotli-python-1.0.9  | 347 KB    | 4          |   5% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cffi-1.17.1          | 311 KB    | 5          |   5% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 3          |   4% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cffi-1.17.1          | 311 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | ##8        |  28% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "brotli-python-1.0.9  | 347 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libjpeg-turbo-2.1.4  | 1.3 MB    | #####5     |  56% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 3          |   4% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | ###        |  31% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libjpeg-turbo-2.1.4  | 1.3 MB    | ######7    |  68% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 4          |   4% \n",
      "pytorch-2.5.1        | 150.6 MB  | 4          |   5% \n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | ###2       |  32% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libjpeg-turbo-2.1.4  | 1.3 MB    | #######7   |  77% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 5          |   5% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libjpeg-turbo-2.1.4  | 1.3 MB    | #########  |  90% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | ###5       |  36% \u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 5          |   6% \n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | ###8       |  39% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libjpeg-turbo-2.1.4  | 1.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libjpeg-turbo-2.1.4  | 1.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 5          |   6% \n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | ####1      |  41% \u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 6          |   6% \n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | ####4      |  44% \u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 7          |   7% \n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | ####8      |  49% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | #####1     |  51% \u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 7          |   7% \n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | #####6     |  56% \u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 7          |   8% \n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | ######1    |  61% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | ######7    |  68% \u001b[A\u001b[A\n",
      "\n",
      "numpy-base-2.0.1     | 7.1 MB    | ########## | 100% \u001b[A\n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | #######2   |  72% \u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 8          |   8% \n",
      "\n",
      "\n",
      "\n",
      "torchaudio-2.5.1     | 5.9 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "intel-openmp-2025.0. | 1.8 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 8          |   9% \n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | #######6   |  76% \u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 8          |   9% \n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | ########4  |  84% \u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 9          |   9% \n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | #########1 |  92% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libxml2-2.13.7       | 2.9 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | 9          |  10% \n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | #########8 |  99% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | ########## | 100% \u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | #          |  10% \n",
      "pytorch-2.5.1        | 150.6 MB  | #          |  11% \n",
      "pytorch-2.5.1        | 150.6 MB  | #1         |  11% \n",
      "pytorch-2.5.1        | 150.6 MB  | #1         |  11% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sympy-1.13.3         | 4.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | #1         |  12% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pillow-11.1.0        | 902 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pillow-11.1.0        | 902 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | #2         |  12% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "zstd-1.5.6           | 708 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libtiff-4.5.1        | 1.0 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lcms2-2.16           | 566 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lcms2-2.16           | 566 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | #2         |  13% \n",
      "pytorch-2.5.1        | 150.6 MB  | #2         |  13% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libpng-1.6.39        | 369 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libpng-1.6.39        | 369 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mpmath-1.3.0         | 429 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mpmath-1.3.0         | 429 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | #3         |  13% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "zstandard-0.23.0     | 351 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "zstandard-0.23.0     | 351 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | #3         |  14% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "freetype-2.10.4      | 489 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "freetype-2.10.4      | 489 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | #4         |  14% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "brotli-python-1.0.9  | 347 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "brotli-python-1.0.9  | 347 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | #4         |  15% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cffi-1.17.1          | 311 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cffi-1.17.1          | 311 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "jpeg-9e              | 366 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "jpeg-9e              | 366 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | #5         |  15% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | #5         |  16% \n",
      "pytorch-2.5.1        | 150.6 MB  | #6         |  16% \n",
      "pytorch-2.5.1        | 150.6 MB  | #6         |  17% \n",
      "pytorch-2.5.1        | 150.6 MB  | #7         |  17% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libjpeg-turbo-2.1.4  | 1.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | #7         |  18% \n",
      "pytorch-2.5.1        | 150.6 MB  | #8         |  19% \n",
      "pytorch-2.5.1        | 150.6 MB  | #9         |  19% \n",
      "pytorch-2.5.1        | 150.6 MB  | #9         |  20% \n",
      "pytorch-2.5.1        | 150.6 MB  | ##         |  20% \n",
      "pytorch-2.5.1        | 150.6 MB  | ##         |  20% \n",
      "pytorch-2.5.1        | 150.6 MB  | ##         |  21% \n",
      "pytorch-2.5.1        | 150.6 MB  | ##1        |  21% \n",
      "pytorch-2.5.1        | 150.6 MB  | ##1        |  22% \n",
      "pytorch-2.5.1        | 150.6 MB  | ##1        |  22% \n",
      "pytorch-2.5.1        | 150.6 MB  | ##2        |  22% \n",
      "pytorch-2.5.1        | 150.6 MB  | ##2        |  23% \n",
      "pytorch-2.5.1        | 150.6 MB  | ##2        |  23% \n",
      "pytorch-2.5.1        | 150.6 MB  | ##3        |  23% \n",
      "pytorch-2.5.1        | 150.6 MB  | ##3        |  24% \n",
      "pytorch-2.5.1        | 150.6 MB  | ##4        |  25% \n",
      "pytorch-2.5.1        | 150.6 MB  | ##5        |  25% \n",
      "pytorch-2.5.1        | 150.6 MB  | ##5        |  26% \n",
      "pytorch-2.5.1        | 150.6 MB  | ##6        |  26% \n",
      "pytorch-2.5.1        | 150.6 MB  | ##6        |  27% \n",
      "pytorch-2.5.1        | 150.6 MB  | ##7        |  27% \n",
      "pytorch-2.5.1        | 150.6 MB  | ##7        |  28% \n",
      "pytorch-2.5.1        | 150.6 MB  | ##8        |  28% \n",
      "pytorch-2.5.1        | 150.6 MB  | ##9        |  29% \n",
      "pytorch-2.5.1        | 150.6 MB  | ##9        |  30% \n",
      "pytorch-2.5.1        | 150.6 MB  | ##9        |  30% \n",
      "pytorch-2.5.1        | 150.6 MB  | ###        |  31% \n",
      "\n",
      "\n",
      "torchvision-0.20.1   | 6.7 MB    | ########## | 100% \u001b[A\u001b[A\n",
      "pytorch-2.5.1        | 150.6 MB  | ###1       |  31% \n",
      "pytorch-2.5.1        | 150.6 MB  | ###1       |  31% \n",
      "pytorch-2.5.1        | 150.6 MB  | ###1       |  32% \n",
      "pytorch-2.5.1        | 150.6 MB  | ###2       |  32% \n",
      "pytorch-2.5.1        | 150.6 MB  | ###2       |  33% \n",
      "pytorch-2.5.1        | 150.6 MB  | ###3       |  34% \n",
      "pytorch-2.5.1        | 150.6 MB  | ###4       |  34% \n",
      "pytorch-2.5.1        | 150.6 MB  | ###4       |  34% \n",
      "pytorch-2.5.1        | 150.6 MB  | ###4       |  35% \n",
      "pytorch-2.5.1        | 150.6 MB  | ###5       |  35% \n",
      "pytorch-2.5.1        | 150.6 MB  | ###6       |  36% \n",
      "pytorch-2.5.1        | 150.6 MB  | ###6       |  37% \n",
      "pytorch-2.5.1        | 150.6 MB  | ###6       |  37% \n",
      "pytorch-2.5.1        | 150.6 MB  | ###7       |  37% \n",
      "pytorch-2.5.1        | 150.6 MB  | ###7       |  38% \n",
      "pytorch-2.5.1        | 150.6 MB  | ###8       |  38% \n",
      "pytorch-2.5.1        | 150.6 MB  | ###8       |  39% \n",
      "pytorch-2.5.1        | 150.6 MB  | ###8       |  39% \n",
      "pytorch-2.5.1        | 150.6 MB  | ###9       |  39% \n",
      "pytorch-2.5.1        | 150.6 MB  | ###9       |  40% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####       |  41% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####       |  41% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####1      |  41% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####1      |  41% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####1      |  42% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####2      |  42% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####2      |  42% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####2      |  43% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####2      |  43% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####3      |  43% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####3      |  43% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####3      |  44% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####4      |  44% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####4      |  45% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####4      |  45% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####5      |  45% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####5      |  46% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####6      |  46% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####6      |  46% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####6      |  47% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####7      |  47% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####7      |  48% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####8      |  49% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####9      |  49% \n",
      "pytorch-2.5.1        | 150.6 MB  | ####9      |  50% \n",
      "pytorch-2.5.1        | 150.6 MB  | #####      |  50% \n",
      "pytorch-2.5.1        | 150.6 MB  | #####      |  51% \n",
      "pytorch-2.5.1        | 150.6 MB  | #####1     |  51% \n",
      "pytorch-2.5.1        | 150.6 MB  | #####2     |  52% \n",
      "pytorch-2.5.1        | 150.6 MB  | #####2     |  53% \n",
      "pytorch-2.5.1        | 150.6 MB  | #####3     |  53% \n",
      "pytorch-2.5.1        | 150.6 MB  | #####4     |  54% \n",
      "pytorch-2.5.1        | 150.6 MB  | #####5     |  55% \n",
      "pytorch-2.5.1        | 150.6 MB  | #####5     |  56% \n",
      "pytorch-2.5.1        | 150.6 MB  | #####6     |  56% \n",
      "pytorch-2.5.1        | 150.6 MB  | #####6     |  57% \n",
      "pytorch-2.5.1        | 150.6 MB  | #####7     |  57% \n",
      "pytorch-2.5.1        | 150.6 MB  | #####8     |  58% \n",
      "pytorch-2.5.1        | 150.6 MB  | #####8     |  58% \n",
      "pytorch-2.5.1        | 150.6 MB  | #####8     |  59% \n",
      "pytorch-2.5.1        | 150.6 MB  | #####9     |  59% \n",
      "pytorch-2.5.1        | 150.6 MB  | #####9     |  60% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######     |  60% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######     |  60% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######     |  61% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######     |  61% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######1    |  61% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######1    |  62% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######1    |  62% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######2    |  62% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######2    |  62% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######2    |  63% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######2    |  63% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######3    |  63% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######3    |  63% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######3    |  63% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######3    |  64% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######3    |  64% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######4    |  64% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######4    |  64% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######4    |  64% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######4    |  65% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######4    |  65% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######5    |  65% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######5    |  65% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######5    |  66% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######5    |  66% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######6    |  66% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######6    |  66% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######6    |  66% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######6    |  67% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######6    |  67% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######6    |  67% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######7    |  67% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######7    |  67% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######7    |  68% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######7    |  68% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######7    |  68% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######8    |  68% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######8    |  68% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######8    |  69% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######8    |  69% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######9    |  69% \n",
      "pytorch-2.5.1        | 150.6 MB  | ######9    |  70% \n",
      "pytorch-2.5.1        | 150.6 MB  | #######    |  70% \n",
      "pytorch-2.5.1        | 150.6 MB  | #######    |  70% \n",
      "pytorch-2.5.1        | 150.6 MB  | #######    |  71% \n",
      "pytorch-2.5.1        | 150.6 MB  | #######1   |  71% \n",
      "pytorch-2.5.1        | 150.6 MB  | #######1   |  72% \n",
      "pytorch-2.5.1        | 150.6 MB  | #######2   |  72% \n",
      "pytorch-2.5.1        | 150.6 MB  | #######2   |  73% \n",
      "pytorch-2.5.1        | 150.6 MB  | #######3   |  73% \n",
      "pytorch-2.5.1        | 150.6 MB  | #######3   |  74% \n",
      "pytorch-2.5.1        | 150.6 MB  | #######4   |  74% \n",
      "pytorch-2.5.1        | 150.6 MB  | #######4   |  75% \n",
      "pytorch-2.5.1        | 150.6 MB  | #######5   |  75% \n",
      "pytorch-2.5.1        | 150.6 MB  | #######5   |  76% \n",
      "pytorch-2.5.1        | 150.6 MB  | #######6   |  76% \n",
      "pytorch-2.5.1        | 150.6 MB  | #######6   |  77% \n",
      "pytorch-2.5.1        | 150.6 MB  | #######7   |  77% \n",
      "pytorch-2.5.1        | 150.6 MB  | #######7   |  78% \n",
      "pytorch-2.5.1        | 150.6 MB  | #######7   |  78% \n",
      "pytorch-2.5.1        | 150.6 MB  | #######8   |  78% \n",
      "pytorch-2.5.1        | 150.6 MB  | #######8   |  79% \n",
      "pytorch-2.5.1        | 150.6 MB  | #######9   |  79% \n",
      "pytorch-2.5.1        | 150.6 MB  | #######9   |  79% \n",
      "pytorch-2.5.1        | 150.6 MB  | #######9   |  80% \n",
      "pytorch-2.5.1        | 150.6 MB  | ########   |  80% \n",
      "pytorch-2.5.1        | 150.6 MB  | ########   |  81% \n",
      "pytorch-2.5.1        | 150.6 MB  | ########1  |  81% \n",
      "pytorch-2.5.1        | 150.6 MB  | ########1  |  82% \n",
      "pytorch-2.5.1        | 150.6 MB  | ########2  |  82% \n",
      "pytorch-2.5.1        | 150.6 MB  | ########2  |  83% \n",
      "pytorch-2.5.1        | 150.6 MB  | ########3  |  83% \n",
      "pytorch-2.5.1        | 150.6 MB  | ########3  |  84% \n",
      "pytorch-2.5.1        | 150.6 MB  | ########4  |  85% \n",
      "pytorch-2.5.1        | 150.6 MB  | ########5  |  85% \n",
      "pytorch-2.5.1        | 150.6 MB  | ########5  |  86% \n",
      "pytorch-2.5.1        | 150.6 MB  | ########6  |  87% \n",
      "pytorch-2.5.1        | 150.6 MB  | ########7  |  88% \n",
      "pytorch-2.5.1        | 150.6 MB  | ########8  |  88% \n",
      "pytorch-2.5.1        | 150.6 MB  | ########9  |  89% \n",
      "pytorch-2.5.1        | 150.6 MB  | #########  |  90% \n",
      "pytorch-2.5.1        | 150.6 MB  | #########1 |  91% \n",
      "pytorch-2.5.1        | 150.6 MB  | #########2 |  92% \n",
      "pytorch-2.5.1        | 150.6 MB  | #########2 |  93% \n",
      "pytorch-2.5.1        | 150.6 MB  | #########3 |  93% \n",
      "pytorch-2.5.1        | 150.6 MB  | #########4 |  94% \n",
      "pytorch-2.5.1        | 150.6 MB  | #########5 |  95% \n",
      "pytorch-2.5.1        | 150.6 MB  | #########6 |  96% \n",
      "pytorch-2.5.1        | 150.6 MB  | #########7 |  97% \n",
      "pytorch-2.5.1        | 150.6 MB  | #########8 |  98% \n",
      "pytorch-2.5.1        | 150.6 MB  | #########9 |  99% \n",
      "pytorch-2.5.1        | 150.6 MB  | #########9 | 100% \n",
      "pytorch-2.5.1        | 150.6 MB  | ########## | 100% \n",
      "pytorch-2.5.1        | 150.6 MB  | ########## | 100% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                      \n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "                                                     \n",
      "\n",
      "\n",
      "                                                     \u001b[A\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A done\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 24.11.3\n",
      "    latest version: 25.3.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install pytorch torchvision torchaudio cpuonly -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60b58e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from L_score import L_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69b71f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>clicked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15364</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13371</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52339</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40119</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39677</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  clicked\n",
       "15364      1        0\n",
       "13371      8        0\n",
       "52339      7        0\n",
       "40119      7        0\n",
       "39677      4        0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1db225dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HackatonDataset(Dataset):\n",
    "    def __init__(self, X, y_df):\n",
    "        \"\"\"\n",
    "        Konstruktor przyjmuje macierz cech (X) oraz DataFrame y_df,\n",
    "        w którym kolumna 'label' to etykieta, a 'clicked' to informacja aposteriori.\n",
    "        \"\"\"\n",
    "        # Konwersja DataFrame na tablicę NumPy\n",
    "        self.X = torch.tensor(X.values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y_df[\"label\"].values, dtype=torch.long)\n",
    "        self.clicked = torch.tensor(y_df[\"clicked\"].values, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], self.clicked[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699a83f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/20, Training Loss: 2.3511\n",
      "Epoch  2/20, Training Loss: 2.3211\n",
      "Epoch  3/20, Training Loss: 2.3202\n",
      "Epoch  4/20, Training Loss: 2.3202\n",
      "Epoch  5/20, Training Loss: 2.3203\n",
      "Epoch  6/20, Training Loss: 2.3201\n",
      "Epoch  7/20, Training Loss: 2.3200\n",
      "Epoch  8/20, Training Loss: 2.3202\n",
      "Epoch  9/20, Training Loss: 2.3200\n",
      "Epoch 10/20, Training Loss: 2.3203\n",
      "Epoch 11/20, Training Loss: 2.3202\n",
      "Epoch 12/20, Training Loss: 2.3200\n",
      "Epoch 13/20, Training Loss: 2.3200\n",
      "Epoch 14/20, Training Loss: 2.3201\n",
      "Epoch 15/20, Training Loss: 2.3199\n",
      "Epoch 16/20, Training Loss: 2.3199\n",
      "Epoch 17/20, Training Loss: 2.3199\n",
      "Epoch 18/20, Training Loss: 2.3199\n",
      "Epoch 19/20, Training Loss: 2.3200\n",
      "Epoch 20/20, Training Loss: 2.3200\n",
      "\n",
      "Validation Loss: 2.3217\n",
      "L_score na zbiorze walidacyjnym: 0.1061\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Wczytanie i przygotowanie danych ---\n",
    "\n",
    "# Wczytujemy dane z plików x_train.csv oraz y_train.csv\n",
    "X_train = pd.read_csv(\"data/x_train.csv\")\n",
    "y_train = pd.read_csv(\"data/y_train.csv\")  # Powinien zawierać kolumny: 'label' i 'clicked'\n",
    "X_val = pd.read_csv(\"data/x_valid.csv\")\n",
    "y_val = pd.read_csv(\"data/y_valid.csv\")  # Powinien zawierać kolumny: 'label' i 'clicked'\n",
    "\n",
    "# Upewniamy się, że X zawiera tylko cechy numeryczne (dostosuj, jeśli potrzeba)\n",
    "X_train= X_train.select_dtypes(include=[np.number])\n",
    "X_val = X_val.select_dtypes(include=[np.number])\n",
    "\n",
    "\n",
    "# Standaryzacja cech\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "\n",
    "# Tworzymy zestawy danych i DataLoadery\n",
    "train_dataset = HackatonDataset(X_train_scaled, y_train)\n",
    "val_dataset   = HackatonDataset(X_val_scaled, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# --- 3. Definicja modelu (logistyczna regresja) ---\n",
    "\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.linear(x)\n",
    "        return logits\n",
    "\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "num_classes = 10  # Zakładamy 10 unikalnych wartości layout_type\n",
    "model = LogisticRegressionModel(input_dim, num_classes)\n",
    "\n",
    "# Wybieramy optymalizator\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# --- 4. Definicja customowego lossu ---\n",
    "\n",
    "def custom_loss_fn(logits, target, clicked, lambda_val):\n",
    "    \"\"\"\n",
    "    Oblicza standardową funkcję cross-entropy (per próbka) i modyfikuje ją według reguł:\n",
    "    \n",
    "    - Jeżeli clicked == 0:\n",
    "        * Jeżeli predykcja poprawna: loss += lambda_val\n",
    "        * Jeżeli predykcja błędna: loss += (lambda_val / 10)\n",
    "    - Jeżeli clicked == 1:\n",
    "        * Jeżeli predykcja poprawna: loss -= lambda_val\n",
    "        * Jeżeli predykcja błędna: loss += (lambda_val / 10)\n",
    "        \n",
    "    params:\n",
    "      logits    : logity wyjściowe z modelu (tensor)\n",
    "      target    : prawdziwe etykiety (tensor, dtype long)\n",
    "      clicked   : informacje o kliknięciu (tensor, dtype float, wartości 0 lub 1)\n",
    "      lambda_val: parametr lambda (float)\n",
    "      \n",
    "    return:\n",
    "      średnia zmodyfikowana strata (loss)\n",
    "    \"\"\"\n",
    "    # Obliczamy cross-entropy (bez redukcji, czyli per próbka)\n",
    "    ce_loss = F.cross_entropy(logits, target, reduction=\"none\")\n",
    "    \n",
    "    # Predykcje – uzywamy argmax\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    # Tensor boolowski: czy predykcja jest poprawna\n",
    "    correct = preds.eq(target)\n",
    "    \n",
    "    # Inicjujemy modyfikację lossu\n",
    "    adjustment = torch.zeros_like(ce_loss)\n",
    "    \n",
    "    # Dla próbek, gdzie clicked == 0:\n",
    "    mask0 = (clicked == 0)\n",
    "    # Jeśli predykcja poprawna -> +lambda, jeśli błędna -> +(lambda/10)\n",
    "    adjustment[mask0] = torch.where(correct[mask0], lambda_val, lambda_val/10)\n",
    "    \n",
    "    # Dla próbek, gdzie clicked == 1:\n",
    "    mask1 = (clicked == 1)\n",
    "    # Jeśli predykcja poprawna -> -lambda, jeśli błędna -> +(lambda/10)\n",
    "    adjustment[mask1] = torch.where(correct[mask1], -lambda_val, lambda_val/10)\n",
    "    \n",
    "    total_loss = ce_loss + adjustment\n",
    "    return total_loss.mean()\n",
    "\n",
    "# --- 5. Pętla treningowa wykorzystująca custom loss ---\n",
    "\n",
    "lambda_val = 0.1  # Ustalona wartość parametru lambda – można eksperymentować\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    for batch in train_loader:\n",
    "        X_batch, y_batch, clicked_batch = batch\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_batch)\n",
    "        loss = custom_loss_fn(logits, y_batch, clicked_batch, lambda_val)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "    print(f\"Epoch {epoch+1:2d}/{num_epochs}, Training Loss: {np.mean(epoch_losses):.4f}\")\n",
    "\n",
    "# --- 6. Walidacja modelu ---\n",
    "\n",
    "model.eval()\n",
    "val_losses = []\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "all_clicked = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        X_batch, y_batch, clicked_batch = batch\n",
    "        logits = model(X_batch)\n",
    "        loss = custom_loss_fn(logits, y_batch, clicked_batch, lambda_val)\n",
    "        val_losses.append(loss.item())\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(y_batch.cpu().numpy())\n",
    "        all_clicked.extend(clicked_batch.cpu().numpy())\n",
    "        \n",
    "avg_val_loss = np.mean(val_losses)\n",
    "print(f\"\\nValidation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "# --- 7. Ocena modelu za pomocą metryki L_score ---\n",
    "\n",
    "\n",
    "# Przygotowanie zbioru walidacyjnego do obliczania L_score\n",
    "val_df = y_val.copy()\n",
    "# Dodajemy kolumnę z predykcjami uzyskanymi z modelu\n",
    "val_df['y_pred'] = all_preds\n",
    "\n",
    "l_score_val = L_score(val_df[['label','clicked']], val_df['y_pred'])\n",
    "print(f\"L_score na zbiorze walidacyjnym: {l_score_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20c79ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd29bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/20, Training Loss: 2.3503\n",
      "Epoch  2/20, Training Loss: 2.3219\n",
      "Epoch  3/20, Training Loss: 2.3200\n",
      "Epoch  4/20, Training Loss: 2.3196\n",
      "Epoch  5/20, Training Loss: 2.3193\n",
      "Epoch  6/20, Training Loss: 2.3194\n",
      "Epoch  7/20, Training Loss: 2.3189\n",
      "Epoch  8/20, Training Loss: 2.3184\n",
      "Epoch  9/20, Training Loss: 2.3186\n",
      "Epoch 10/20, Training Loss: 2.3186\n",
      "Epoch 11/20, Training Loss: 2.3181\n",
      "Epoch 12/20, Training Loss: 2.3183\n",
      "Epoch 13/20, Training Loss: 2.3181\n",
      "Epoch 14/20, Training Loss: 2.3184\n",
      "Epoch 15/20, Training Loss: 2.3183\n",
      "Epoch 16/20, Training Loss: 2.3184\n",
      "Epoch 17/20, Training Loss: 2.3183\n",
      "Epoch 18/20, Training Loss: 2.3181\n",
      "Epoch 19/20, Training Loss: 2.3183\n",
      "Epoch 20/20, Training Loss: 2.3178\n",
      "\n",
      "Validation Loss: 2.3186\n",
      "L_score na zbiorze walidacyjnym: 0.0964\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Wczytanie i przygotowanie danych ---\n",
    "\n",
    "X_train = pd.read_csv(\"data/x_train.csv\")\n",
    "y_train = pd.read_csv(\"data/y_train.csv\")  # Powinien zawierać kolumny: 'label' i 'clicked'\n",
    "X_val = pd.read_csv(\"data/x_valid.csv\")\n",
    "y_val = pd.read_csv(\"data/y_valid.csv\")  # Powinien zawierać kolumny: 'label' i 'clicked'\n",
    "\n",
    "X_train= X_train.select_dtypes(include=[np.number])\n",
    "X_val = X_val.select_dtypes(include=[np.number])\n",
    "\n",
    "# Standaryzacja cech\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "\n",
    "# Tworzymy zestawy danych i DataLoadery\n",
    "train_dataset = HackatonDataset(X_train_scaled, y_train)\n",
    "val_dataset   = HackatonDataset(X_val_scaled, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# --- 3. Definicja nowego modelu sieci neuronowej ---\n",
    "\n",
    "class BetterMLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(BetterMLP, self).__init__()\n",
    "        # Pierwsza warstwa: 64 neurony + BatchNorm + Dropout\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        \n",
    "        # Druga warstwa: 32 neurony + BatchNorm + Dropout\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        # Warstwa wyjściowa\n",
    "        self.fc3 = nn.Linear(32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        logits = self.fc3(x)\n",
    "        return logits\n",
    "\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "num_classes = 10  # Zakładamy 10 unikalnych klas\n",
    "model = BetterMLP(input_dim, num_classes)\n",
    "\n",
    "# Wybieramy optymalizator\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# --- 4. Definicja customowego lossu ---\n",
    "\n",
    "def custom_loss_fn(logits, target, clicked, lambda_val):\n",
    "    \"\"\"\n",
    "    Oblicza standardową funkcję cross-entropy (per próbka) i modyfikuje ją według reguł:\n",
    "    \n",
    "    - Jeżeli clicked == 0:\n",
    "        * Jeżeli predykcja poprawna: loss += lambda_val\n",
    "        * Jeżeli predykcja błędna: loss += (lambda_val / 10)\n",
    "    - Jeżeli clicked == 1:\n",
    "        * Jeżeli predykcja poprawna: loss -= lambda_val\n",
    "        * Jeżeli predykcja błędna: loss += (lambda_val / 10)\n",
    "        \n",
    "    params:\n",
    "      logits    : logity wyjściowe z modelu (tensor)\n",
    "      target    : prawdziwe etykiety (tensor, dtype long)\n",
    "      clicked   : informacje o kliknięciu (tensor, dtype float, wartości 0 lub 1)\n",
    "      lambda_val: parametr lambda (float)\n",
    "      \n",
    "    return:\n",
    "      średnia zmodyfikowana strata (loss)\n",
    "    \"\"\"\n",
    "    ce_loss = F.cross_entropy(logits, target, reduction=\"none\")\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    correct = preds.eq(target)\n",
    "    adjustment = torch.zeros_like(ce_loss)\n",
    "    \n",
    "    mask0 = (clicked == 0)\n",
    "    adjustment[mask0] = torch.where(correct[mask0], lambda_val, lambda_val/10)\n",
    "    \n",
    "    mask1 = (clicked == 1)\n",
    "    adjustment[mask1] = torch.where(correct[mask1], -lambda_val, lambda_val/10)\n",
    "    \n",
    "    total_loss = ce_loss + adjustment\n",
    "    return total_loss.mean()\n",
    "\n",
    "# --- 5. Pętla treningowa wykorzystująca custom loss ---\n",
    "\n",
    "lambda_val = 0.1  # Ustalona wartość parametru lambda – można eksperymentować\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    for batch in train_loader:\n",
    "        X_batch, y_batch, clicked_batch = batch\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_batch)\n",
    "        loss = custom_loss_fn(logits, y_batch, clicked_batch, lambda_val)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "    print(f\"Epoch {epoch+1:2d}/{num_epochs}, Training Loss: {np.mean(epoch_losses):.4f}\")\n",
    "\n",
    "# --- 6. Walidacja modelu ---\n",
    "\n",
    "model.eval()\n",
    "val_losses = []\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "all_clicked = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        X_batch, y_batch, clicked_batch = batch\n",
    "        logits = model(X_batch)\n",
    "        loss = custom_loss_fn(logits, y_batch, clicked_batch, lambda_val)\n",
    "        val_losses.append(loss.item())\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(y_batch.cpu().numpy())\n",
    "        all_clicked.extend(clicked_batch.cpu().numpy())\n",
    "        \n",
    "avg_val_loss = np.mean(val_losses)\n",
    "print(f\"\\nValidation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "# Przygotowanie zbioru walidacyjnego do obliczania L_score\n",
    "val_df = y_val.copy()\n",
    "val_df['y_pred'] = all_preds\n",
    "\n",
    "l_score_val = L_score(val_df[['label','clicked']], val_df['y_pred'])\n",
    "print(f\"L_score na zbiorze walidacyjnym: {l_score_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d44c8651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/20, Training Loss: 2.3484\n",
      "Epoch  2/20, Training Loss: 2.3210\n",
      "Epoch  3/20, Training Loss: 2.3198\n",
      "Epoch  4/20, Training Loss: 2.3195\n",
      "Epoch  5/20, Training Loss: 2.3192\n",
      "Epoch  6/20, Training Loss: 2.3187\n",
      "Epoch  7/20, Training Loss: 2.3188\n",
      "Epoch  8/20, Training Loss: 2.3187\n",
      "Epoch  9/20, Training Loss: 2.3182\n",
      "Epoch 10/20, Training Loss: 2.3184\n",
      "Epoch 11/20, Training Loss: 2.3184\n",
      "Epoch 12/20, Training Loss: 2.3183\n",
      "Epoch 13/20, Training Loss: 2.3182\n",
      "Epoch 14/20, Training Loss: 2.3181\n",
      "Epoch 15/20, Training Loss: 2.3180\n",
      "Epoch 16/20, Training Loss: 2.3181\n",
      "Epoch 17/20, Training Loss: 2.3179\n",
      "Epoch 18/20, Training Loss: 2.3182\n",
      "Epoch 19/20, Training Loss: 2.3180\n",
      "Epoch 20/20, Training Loss: 2.3179\n",
      "\n",
      "Validation Loss: 2.3016\n",
      "L_score na zbiorze walidacyjnym: 0.1031\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled = pd.read_csv(\"data/feature_engineering/processed_x_train.csv\")\n",
    "X_val_scaled = pd.read_csv(\"data/feature_engineering/processed_x_valid.csv\")\n",
    "y_train = pd.read_csv(\"data/y_train.csv\")\n",
    "y_val = pd.read_csv(\"data/y_valid.csv\")\n",
    "\n",
    "# Tworzymy zestawy danych i DataLoadery\n",
    "train_dataset = HackatonDataset(X_train_scaled, y_train)\n",
    "val_dataset   = HackatonDataset(X_val_scaled, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# --- 3. Definicja nowego modelu sieci neuronowej ---\n",
    "\n",
    "class BetterMLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(BetterMLP, self).__init__()\n",
    "        # Pierwsza warstwa: 64 neurony + BatchNorm + Dropout\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        \n",
    "        # Druga warstwa: 32 neurony + BatchNorm + Dropout\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        # Warstwa wyjściowa\n",
    "        self.fc3 = nn.Linear(32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        logits = self.fc3(x)\n",
    "        return logits\n",
    "\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "num_classes = 10  # Zakładamy 10 unikalnych klas\n",
    "model = BetterMLP(input_dim, num_classes)\n",
    "\n",
    "# Wybieramy optymalizator\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# --- 4. Definicja customowego lossu ---\n",
    "\n",
    "def custom_loss_fn(logits, target, clicked, lambda_val):\n",
    "    \"\"\"\n",
    "    Oblicza standardową funkcję cross-entropy (per próbka) i modyfikuje ją według reguł:\n",
    "    \n",
    "    - Jeżeli clicked == 0:\n",
    "        * Jeżeli predykcja poprawna: loss += lambda_val\n",
    "        * Jeżeli predykcja błędna: loss += (lambda_val / 10)\n",
    "    - Jeżeli clicked == 1:\n",
    "        * Jeżeli predykcja poprawna: loss -= lambda_val\n",
    "        * Jeżeli predykcja błędna: loss += (lambda_val / 10)\n",
    "        \n",
    "    params:\n",
    "      logits    : logity wyjściowe z modelu (tensor)\n",
    "      target    : prawdziwe etykiety (tensor, dtype long)\n",
    "      clicked   : informacje o kliknięciu (tensor, dtype float, wartości 0 lub 1)\n",
    "      lambda_val: parametr lambda (float)\n",
    "      \n",
    "    return:\n",
    "      średnia zmodyfikowana strata (loss)\n",
    "    \"\"\"\n",
    "    ce_loss = F.cross_entropy(logits, target, reduction=\"none\")\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    correct = preds.eq(target)\n",
    "    adjustment = torch.zeros_like(ce_loss)\n",
    "    \n",
    "    mask0 = (clicked == 0)\n",
    "    adjustment[mask0] = torch.where(correct[mask0], lambda_val, lambda_val/10)\n",
    "    \n",
    "    mask1 = (clicked == 1)\n",
    "    adjustment[mask1] = torch.where(correct[mask1], -lambda_val, lambda_val/10)\n",
    "    \n",
    "    total_loss = ce_loss + adjustment\n",
    "    return total_loss.mean()\n",
    "\n",
    "# --- 5. Pętla treningowa wykorzystująca custom loss ---\n",
    "\n",
    "lambda_val = 0.1  # Ustalona wartość parametru lambda – można eksperymentować\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    for batch in train_loader:\n",
    "        X_batch, y_batch, clicked_batch = batch\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_batch)\n",
    "        loss = custom_loss_fn(logits, y_batch, clicked_batch, lambda_val)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "    print(f\"Epoch {epoch+1:2d}/{num_epochs}, Training Loss: {np.mean(epoch_losses):.4f}\")\n",
    "\n",
    "# --- 6. Walidacja modelu ---\n",
    "\n",
    "model.eval()\n",
    "val_losses = []\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "all_clicked = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        X_batch, y_batch, clicked_batch = batch\n",
    "        logits = model(X_batch)\n",
    "        loss = custom_loss_fn(logits, y_batch, clicked_batch, lambda_val)\n",
    "        val_losses.append(loss.item())\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(y_batch.cpu().numpy())\n",
    "        all_clicked.extend(clicked_batch.cpu().numpy())\n",
    "        \n",
    "avg_val_loss = np.mean(val_losses)\n",
    "print(f\"\\nValidation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "# Przygotowanie zbioru walidacyjnego do obliczania L_score\n",
    "val_df = y_val.copy()\n",
    "val_df['y_pred'] = all_preds\n",
    "\n",
    "l_score_val = L_score(val_df[['label','clicked']], val_df['y_pred'])\n",
    "print(f\"L_score na zbiorze walidacyjnym: {l_score_val:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "combainslot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
